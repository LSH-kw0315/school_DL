{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"provenance":[{"file_id":"14EbZY7wE73yoyqEF3Q4V4V0hcJ2xSJdo","timestamp":1712296751399},{"file_id":"1M86QKUYfVMpRL0IxvBdwfE3LAGt7jl3v","timestamp":1679208900892},{"file_id":"1oook0YohWE0ixXTC7QXBBekJGlPIjtWQ","timestamp":1651650497064},{"file_id":"1ASblNicAc3-HrzR7FWHvJ3NxE3OkEF79","timestamp":1646227867852},{"file_id":"https://github.com/rickiepark/deep-learning-with-python-notebooks/blob/master/2.1-a-first-look-at-a-neural-network.ipynb","timestamp":1611894898932}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"cL0Fa8CzavHX"},"source":["# 신경망과의 세 번째 만남\n","by uramoon@kw.ac.kr (<a href=\"https://raw.githubusercontent.com/ronreiter/interactive-tutorials/master/LICENSE\">Apache 2.0 License</a>)\n","\n","2004년 MS 연구소에서 발표한 논문에 포함된 MLP (Multi-Layer Perceptron, 유닛 800개 들어간 은닉층 하나만 사용)의 MNIST 테스트 정확도는 98.4%입니다. 같은 논문에서 훈련 데이터를 늘리고 이미지를 이차원 형태로 해석하는 능력을 갖춘 합성곱 신경망 (CNN, Convolution neural network)을 사용했을 때 99.6%를 달성했습니다.\n","\n","\n","\n","본 노트북에서는 MLP의 epochs를 자동으로 설정하여 테스트 정확도를 98.3% 이상으로 만드는 것을 목표로 합니다."]},{"cell_type":"code","metadata":{"id":"hl8n95y_avHS","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1712298712394,"user_tz":-540,"elapsed":8194,"user":{"displayName":"이승헌","userId":"10348056862918872158"}},"outputId":"d6b20ca1-a7d2-4199-ac38-772e9cc3561e"},"source":["import keras\n","keras.__version__"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.15.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","source":["## 데이터셋 불러오기 & 이미지 전처리\n"],"metadata":{"id":"orxCsBOIr2w8"}},{"cell_type":"code","metadata":{"id":"CCBjPiT9avHY","executionInfo":{"status":"ok","timestamp":1712298869980,"user_tz":-540,"elapsed":1284,"user":{"displayName":"이승헌","userId":"10348056862918872158"}}},"source":["# TODO: MNIST 데이터셋 불러오기\n","\n","(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n","\n","# TODO: 이미지 전처리\n","# [0, 255]의 3차원 배열을 [0, 1]의 2차원 배열로 변환\n","train_images = train_images.reshape(train_images.shape[0],28*28)/255.0\n","test_images = test_images.reshape(test_images.shape[0],28*28)/255.0"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## 분류 문제의 출력층과 손실 (loss) 함수\n","\n","출력 유닛의 수가 **2 이상**인 분류 문제에서 출력층의 활성화 함수로는 지난 시간에 사용한 **softmax**를 사용합니다. 출력층의 각 유닛은 일반적으로 $(-\\infty,+\\infty)$의 값을 출력하는데 softmax는 그들 중 가장 큰 값에 가장 높은 확률을 부여합니다. (동시에 모든 확률을 더했을 때 1이 되도록 만듦)\n","\n","\n","손실 (loss) 함수는 출력층의 출력 내용이 이상적인 출력 내용과 얼마나 동떨어졌는지 계산합니다. (loss가 클수록 나쁨)\n","\n","출력 유닛의 수가 **2 이상**인 분류 문제에서 사용할 수 있는 대표적인 손실 함수는 다음의 두 개가 있습니다:\n","\n","1. categorical_crossentropy: 지난 시간에 사용한 함수로 정답 (label)이 5인 경우  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]와 같이 **label을 변환**해야 한다.\n","2. sparse_categorical_crossentropy: 정답 (label)이 5인 경우 5를 [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]로 해석하여 loss를 계산하므로 **label을 변환할 필요가 없다.** (5를 봤을 때 5번째 인덱스의 출력은 1이고, 나머지는 0으로 해석)\n","\n","이 번 노트북에서는 **label을 변환하지 않고, sparse_categorical_crossentropy를 사용해봅시다.**\n","\n","---\n","\n","출력 유닛의 수가 1인 이진 분류 (binary classification)의 출력층에서는 **softmax를 사용하면 안됩니다.** softmax는 여러 개의 출력을 확률로 변환하는데, 출력이 하나 밖에 없으므로 하나의 출력을 무조건 1로 만들어주기 때문입니다. 이진 분류 문제에서는 출력층에서 sigmoid 함수를 사용하여 $(-\\infty,+\\infty)$의 값을 (0, 1)의 값으로 바꿔줍니다. (예: 고양이와 개를 분류할 때 고양이일 확률이 $p$라면, 개일 확률은 $1-p$로 해석합니다.)\n","\n"],"metadata":{"id":"fHwfu4QlI3gT"}},{"cell_type":"markdown","source":["## MLP 만들기\n","\n","문제에 따라서 효율적인 인공신경망 구조가 있으나 직접 해보기 전까지는 어떠한 구조가 잘 동작할 지 알 수 없습니다.<br> 편의상 신경망과의 첫 만남 때 사용한 것과 동일한 네트워크를 사용합니다."],"metadata":{"id":"NrzI8foUsoU7"}},{"cell_type":"code","metadata":{"id":"YAuPjlTTavHb","executionInfo":{"status":"ok","timestamp":1712298890888,"user_tz":-540,"elapsed":504,"user":{"displayName":"이승헌","userId":"10348056862918872158"}}},"source":["# TODO: 네트워크 만들기, loss만 써주세요.\n","from keras import models\n","from keras import layers\n","\n","network = models.Sequential()\n","network.add(layers.Input(784,)) # (784)는 784라는 정수, (784,)는 길이 784인 일차원 배열을 의미\n","network.add(layers.Dense(512, activation='relu'))\n","network.add(layers.Dense(10, activation='softmax'))\n","\n","network.compile(optimizer='rmsprop',\n","                loss='sparse_categorical_crossentropy',\n","                metrics=['accuracy'])"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## EarlyStopping 사용하기\n","\n","https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n","\n","epochs는 훈련 데이터를 반복해서 몇 번 보고 훈련할 것인지 결정합니다. epochs를 무작정 키울 수 없는 것은 인공신경망이 훈련 데이터에 과적합되어 보지 못한 테스트 데이터에서의 성능이 떨어질까 걱정되기 때문입니다. 이를 방지하려면 훈련 데이터의 일부를 훈련 중 볼 수 없는 **검증 데이터**로 활용하면 됩니다.\n","\n","**검증 데이터**를 사용하면 테스트 데이터를 사용하지 않고도 훈련 중에 **테스트 데이터에서의 성능을 미리 가늠**해볼 수 있습니다. 훈련 중 epoch이 끝날 때마다 검증 데이터에서의 성능을 평가하여 과적합 조짐 (훈련 데이터에서의 성능은 올라갔으나 훈련 중 보지 못한 검증 데이터에서의 성능은 하락)이 보이면 훈련을 그만두도록 설정할 수 있습니다."],"metadata":{"id":"iS6BKDqi2Ic2"}},{"cell_type":"code","source":["# TODO: EarlyStopping을 사용하여 훈련하기\n","# Test Accuracy 98.3% 이상을 달성하세요.\n","# 처음부터 훈련하려면 위의 코드블록도 다시 실행하고,\n","# 기존의 신경망으로 이어서 훈련하려면 이 코드 블록만 다시 실행합니다.\n","# (계속 이어서 훈련하면 과적합 문제 발생 가능성이 높아짐)\n","from keras.callbacks import EarlyStopping\n","\n","network.fit(train_images, train_labels, batch_size=128, epochs=10000, # 수정불가: 만 번의 epochs 전에 조기종료를 할 것입니다.\n","            callbacks=EarlyStopping(patience=2),                      # patience: 검증 데이터에서의 val_loss 성능 하락을 몇 번 참을지 적절하게 설정 (수정 가능)\n","            validation_split=0.1)                                     # validation_split: 훈련 데이터에서 검증 데이터로 얼마나 많이 사용할지 적절하게 설정 (수정 가능)\n","\n","test_loss, test_acc = network.evaluate(test_images, test_labels)\n","print(f'Test Accuracy:{test_acc * 100:.2f}%')"],"metadata":{"id":"ndWLQDN8tgcL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712299012659,"user_tz":-540,"elapsed":34582,"user":{"displayName":"이승헌","userId":"10348056862918872158"}},"outputId":"6b53adb2-e5f6-42f5-aff7-b639c2f028ce"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10000\n","422/422 [==============================] - 4s 10ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.0666 - val_accuracy: 0.9813\n","Epoch 2/10000\n","422/422 [==============================] - 5s 12ms/step - loss: 0.0233 - accuracy: 0.9934 - val_loss: 0.0664 - val_accuracy: 0.9823\n","Epoch 3/10000\n","422/422 [==============================] - 4s 10ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.0693 - val_accuracy: 0.9803\n","Epoch 4/10000\n","422/422 [==============================] - 4s 10ms/step - loss: 0.0127 - accuracy: 0.9972 - val_loss: 0.0642 - val_accuracy: 0.9850\n","Epoch 5/10000\n","422/422 [==============================] - 5s 12ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.0637 - val_accuracy: 0.9845\n","Epoch 6/10000\n","422/422 [==============================] - 4s 10ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.0670 - val_accuracy: 0.9848\n","Epoch 7/10000\n","422/422 [==============================] - 4s 10ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.0678 - val_accuracy: 0.9848\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0593 - accuracy: 0.9832\n","Test Accuracy:98.32%\n"]}]},{"cell_type":"markdown","source":["epoch이 진행되며 훈련 데이터에서의 성능은 비교적 꾸준히 좋아지지만 (loss는 낮아지고, accuracy는 높아짐) 검증 데이터로 측정한 val_loss와 val_accuracy는 그렇지 않음을 확인해보세요.\n","\n","---\n","\n","MNIST에서 MLP 사용 시 규제가 크게 효과적이지 않아 검증 데이터 없이 모든 훈련 데이터에 과적합시키면 테스트 성능이 좋게 나오는 경향이 있습니다.\n","\n","일반적으로는 전체 데이터에서 훈련:검증:테스트의 비율을 6:2:2로 설정하거나 MNIST에서와 같이 훈련 데이터와 테스트 데이터가 따로 제공되는 경우에는 훈련 데이터의 20% 정도를 검증 데이터로 사용합니다. (MNIST에서는 20%로 설정하면 좋지 않음)\n","\n","앞으로는 얼마나 많은 epochs을 훈련해야 하는지 감이 없을 때 검증 데이터와 EarlyStopping을 활용해 봅시다. (다만 훈련 데이터가 충분하지 않은 경우에는 모두 훈련 데이터로 사용합니다.)"],"metadata":{"id":"aZgtRErcxhnX"}},{"cell_type":"markdown","source":["## 모델 저장하기\n","\n","1. save 함수 이용 (예: network.save('my_mnist.h5')), 보통 확장자는 h5 사용\n","2. 왼쪽 메뉴에서 폴더 모양의 아이콘 (파일) 클릭\n","3. 방금 저장한 파일을 로컬로 다운로드 하기 (점 세개 클릭하면 다운로드 가능, 파일이 안보이면 새로고침 클릭)\n","4. 다운로드 받은 파일 용량 확인해보기\n","\n","**다운로드한 모델도 제출**합니다."],"metadata":{"id":"r0I7po9WiJtz"}},{"cell_type":"code","source":["network.save(\"2019203021_mnist.h5\")"],"metadata":{"id":"Op_nxUiRiJX6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712299066295,"user_tz":-540,"elapsed":3,"user":{"displayName":"이승헌","userId":"10348056862918872158"}},"outputId":"d9cee95c-0a66-44de-e8a0-a23ba99d5da1"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]}]}