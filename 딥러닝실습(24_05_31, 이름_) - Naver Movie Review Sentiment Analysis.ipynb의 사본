{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1z-XiYwQcVFYjTZ6oEBu782Fq2UQjpQ_i","timestamp":1717134767960},{"file_id":"19vC5fDFajKQJPENDKfpEp27HtEsktRiW","timestamp":1653311358415},{"file_id":"1GH-VebLl1lktLJOvJ4a86R5l8O3dByqt","timestamp":1652330209739}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"0vPHXXbQ3Kcs"},"source":["# 네이버 영화 리뷰 감성분석"]},{"cell_type":"markdown","metadata":{"id":"iOYvI79S4Ier"},"source":["원본 링크 : https://wikidocs.net/44249 (<a href=https://creativecommons.org/licenses/by-nc-sa/2.0/kr/>CC BY-NC-SA 2.0 KR</a>)<br>\n","Modified by uramoon@kw.ac.kr"]},{"cell_type":"markdown","source":["## konlpy 설치\n","런타임 유형을 GPU로 설정하세요."],"metadata":{"id":"gpGVDqmrCBWu"}},{"cell_type":"code","metadata":{"id":"vDohkPU33SJO"},"source":["# 우리말 자연어 처리를 위한 패키지 인스톨\n","!pip install konlpy\n","\n","import tensorflow as tf\n","import pandas as pd\n","import urllib.request\n","import matplotlib.pyplot as plt\n","import re\n","from konlpy.tag import Okt\n","from tqdm import tqdm\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import numpy as np\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 데이터 준비하기"],"metadata":{"id":"sOcJ4cagbpzz"}},{"cell_type":"markdown","source":["### 데이터 다운로드"],"metadata":{"id":"RIX3vgO4EeN4"}},{"cell_type":"code","metadata":{"id":"WAL6cIYwkNqm"},"source":["# 훈련 데이터와 테스트 데이터 다운로드\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 다운받은 훈련 데이터 파일 앞부분 확인, label 0은 부정적 리뷰, 1은 긍정적 리뷰\n","!head ratings_train.txt"],"metadata":{"id":"OfGY6i_gCru5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: 다운받은 테스트 데이터 파일 앞부분 확인\n"],"metadata":{"id":"r2wcmjaCC9W-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### DataFrame으로 변환\n","데이터를 텍스트 파일보다 다루기 쉬운 DataFrame으로 변환합니다."],"metadata":{"id":"KVOhVZWiEgzO"}},{"cell_type":"code","metadata":{"id":"xUU91wXtkOpr"},"source":["# DataFrame으로 읽기\n","train_data = pd.read_table('ratings_train.txt')\n","test_data = pd.read_table('ratings_test.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train_data에서 무작위로 5개 샘플링\n","train_data.sample(5)"],"metadata":{"id":"uEsv26U1Dc6r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: test_data에서 무작위로 5개 샘플링\n"],"metadata":{"id":"WvUvwuFMD44k"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hv2WLeglkV0T"},"source":["# TODO: 샘플 개수 출력\n","# Hint: pandas.DataFrame.size 이용\n","print('훈련 샘플의 개수 :',) # 훈련용 리뷰 개수 출력\n","print('테스트 샘플의 개수 :',) # 테스트용 리뷰 개수 출력"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 레이블 확인\n","부정적 리뷰와 긍정적 리뷰의 비율을 살펴봅시다."],"metadata":{"id":"_NJpoz4AEwUV"}},{"cell_type":"code","source":["# 훈련 데이터\n","train_data['label'].hist()"],"metadata":{"id":"SoDjtJYnFJGa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: 테스트 데이터 label 분포를 그려보세요.\n"],"metadata":{"id":"o0_KLla_Fh7t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 리뷰에서 한글과 공백만 남기기"],"metadata":{"id":"qqTjyjxmFzsH"}},{"cell_type":"code","source":["# train_data 뒷부분 확인\n","train_data.tail(10)"],"metadata":{"id":"8cAWk8CKGFmv"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yP6uj9BxnmNj"},"source":["# train_data의 document열에서 한글만 남기기, 즉 초성 (ㄱ부터 ㅎ까지), 중성 (ㅏ부터 ㅣ까지),\n","# 음절(가부터 힣까지), 공백을 제외한 문자들을 \"\"로 변환\n","train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", regex=True)\n","\n","# 위와 비교해보세요.\n","train_data.tail(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 공백만 남은 리뷰 제거하기\n","한글이 없었던 리뷰는 공백으로 변했기 때문에 제거합니다."],"metadata":{"id":"DsZGzv_5HweQ"}},{"cell_type":"code","metadata":{"id":"W1VTEzepnrDL"},"source":["train_data['document'] = train_data['document'].str.replace(' +$', \"\", regex=True) # 공백으로만 이루어진 리뷰를 \"\"로 변환\n","train_data['document'].replace('', np.nan, inplace=True) # \"\"를 nan값으로 변경\n","print(train_data.isnull().sum()) # nan인 개수 출력"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2PjMgBhuoNKe"},"source":["# 훈련 데이터에서 nan값 지우기\n","train_data = train_data.dropna(how = 'any')\n","print(len(train_data))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 테스트 데이터 전처리하기\n","훈련 데이터와 동일하게 처리합니다."],"metadata":{"id":"4OQo0E-XMZ0a"}},{"cell_type":"code","metadata":{"id":"al5ilRRDodDy"},"source":["# TODO: 한글과 공백만 남기기\n","\n","# TODO: 공백으로만 이루어진 리뷰 제거하기"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 형태소 분석\n","우리말은 영어와는 달리 공백만으로 단어를 완벽하게 분리해낼 수 없기 때문에 Okt (Open-korean-text)라는 형태소 분석기를 사용할 것입니다.<br>\n","Okt는 트위터에서 만든 오픈소스 한국어 처리기인 twitter-korean-text에서 파생됐습니다."],"metadata":{"id":"KW6jRK-ENGPi"}},{"cell_type":"code","metadata":{"id":"UPPf9sPjoBq7"},"source":["okt = Okt()\n","\n","# 자연어 처리에 사용하지 않을 불용어는 정의하기 나름인데 아래의 것들만 사용하겠습니다.\n","stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dcsq7xc4obAj"},"source":["# 훈련 데이터 형태소 분석\n","X_train = []\n","for sentence in tqdm(train_data['document']): # document에서 리뷰 하나씩 가져오기, tqdm이 진행률을 보여줍니다.\n","    tokenized_sentence = okt.morphs(sentence, stem=True) # 하나의 리뷰 형태소 분석\n","    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어를 제거\n","    X_train.append(stopwords_removed_sentence) # X_train에 형태소 분석한 리뷰 추가하기"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 형태소 분석 전후 비교\n","print(train_data['document'][:5])\n","np.array(X_train[:5], dtype=object)"],"metadata":{"id":"k3VrZI6tRUjO"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-QH3hiAomYB"},"source":["X_test = []\n","# TODO: 테스트 데이터의 형태소를 분석하여 X_test에 저장하세요.\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 토큰화"],"metadata":{"id":"IMLl_TKZRSm_"}},{"cell_type":"code","metadata":{"id":"vT71wLflpRVy"},"source":["# 10,000개의 단어만 사용해봅니다.\n","num_words = 10000\n","\n","# TODO: X_train과 X_test 데이터를 합쳐서 적용합니다.\n","# Hint: 지난 주 NLP 노트북의 Tokenizer 참조\n","tokenizer =\n","tokenizer.fit_on_texts(#TODO)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hPfo_5xcqJcB"},"source":["# 단어별 인덱스\n","print(tokenizer.word_index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P87MGN80q7b2"},"source":["# 단어별 등장횟수\n","print(tokenizer.word_counts.items())"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 훈련 데이터 토큰화하기\n","X_train = tokenizer.texts_to_sequences(X_train)"],"metadata":{"id":"DOgqPPq9WlDQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: 테스트 데이터 토큰화하기\n","X_test ="],"metadata":{"id":"L2IhqnpuWtFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pAvQvpo_Acb"},"source":["# TODO: y값 설정하기, NumPy 배열로 만드세요.\n","# Hint: DataFrame에서 label 열을 가져오세요.\n","y_train =\n","y_test ="],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 훈련 데이터에서 리뷰 길이 알아보기\n","인공신경망에 입력할 리뷰의 적정 길이를 알아봅시다."],"metadata":{"id":"798JOr7mUmNF"}},{"cell_type":"code","source":["# 각 리뷰에 단어(토큰)가 몇 개씩 들어있는지 세어봅시다.\n","num_tokens = []\n","\n","# TODO: num_tokens에 각 리뷰의 단어 숫자를 저장하세요.\n","# Hint: X_train[0]은 첫 번째 훈련 데이터의 단어들이 저장되어 있습니다. 그 길이는 len 함수로 알 수 있습니다.\n"],"metadata":{"id":"d2jtMKAQU143"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: num_tokens 리스트를 num_tokens NumPy 배열로 변환하세요.\n"],"metadata":{"id":"Qqq9r7FmVSib"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모든 리뷰에서 사용한 평균 단어의 수는 다음과 같습니다.\n","np.mean(num_tokens)"],"metadata":{"id":"7vo090nzVW1o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: num_tokens에서 평균 + 2 * 표준편차를 구하여 우리가 허용할 최대 단어의 개수인 max_tokens를 설정해보세요.\n","# num_tokens가 정규분포를 따른다면 97% 이상이 max_tokens보다 적은 단어만을 사용할 것입니다.\n","# Hint: np.mean과 np.std 사용\n","\n","max_tokens =\n","max_tokens =\n","max_tokens"],"metadata":{"id":"HiSDIUaxVZcq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# max_tokens보다 짧은 리뷰의 비율을 출력하는 코드\n","# 너무 적다고 생각되면 위에서 3 * 표준편차로 수정해보세요.\n"],"metadata":{"id":"qR7xrzCOVmiZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iIgJvzh2rhug"},"source":["# 전체 데이터의 길이를 max_tokens로 맞춘다.\n","# 기본이 'pre'로 설정되어 있습니다.\n","X_train = pad_sequences(X_train, maxlen=max_tokens)\n","X_test = pad_sequences(X_test, maxlen=max_tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 생성"],"metadata":{"id":"FtGXGgP2bua5"}},{"cell_type":"code","metadata":{"id":"3aGOyv985GYH"},"source":["from tensorflow.keras.layers import Embedding, Dense, LSTM, GRU\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","\n","# TODO: 자유롭게 설정하세요.\n","embedding_size = # 일반적으로 100에서 300\n","es = EarlyStopping(patience=#TODO, restore_best_weights=#TODO)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6nEH8bdvzFt"},"source":["model = Sequential()\n","# 임베딩층 추가\n","model.add(Embedding(input_dim=num_words,      # 사용하는 단어의 개수\n","                    output_dim=embedding_size,# 임베딩 차원\n","                    input_length=max_tokens,  # 리뷰의 길이\n","                    name='layer_embedding'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: 자유롭게 생성하세요.\n","model.add() # GRU나 LSTM 사용\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer=, loss='binary_crossentropy', metrics=['acc'])"],"metadata":{"id":"gkCYTidzXyO2"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7SHHUilxFB3Z"},"source":["# 모델 훈련하기\n","model.fit(X_train, y_train, epochs=10000, callbacks=es, batch_size=64, validation_split=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eOenyOoS_Qt5"},"source":["# TODO: 테스트 데이터로 평가하기\n","# 84.5% 이상을 목표로 합시다.\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 새로운 리뷰 예측해보기"],"metadata":{"id":"ucyY3JVpbwxK"}},{"cell_type":"code","metadata":{"id":"vbvk5X3PPExa"},"source":["# 문자열을 입력하면 위에서 만든 model을 이용해 부정인지 긍정인지 예측해주는 함수\n","\n","def sentiment_predict(new_sentence):\n","  new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence) # 한글과 공백만 남기기\n","  new_sentence = okt.morphs(new_sentence, stem=True) # 형태소 분석\n","  new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n","  encoded = tokenizer.texts_to_sequences([new_sentence]) # 토큰화\n","  pad_new = pad_sequences(encoded, maxlen = max_tokens) # 패딩\n","  score = float(model.predict(pad_new)) # 예측\n","  if(score > 0.5):\n","    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n","  else:\n","    print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tFC0qDlO28Zg"},"source":["sentiment_predict('이 영화 개꿀잼 ㅋㅋㅋ')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s4v-MwEB29Vk"},"source":["sentiment_predict('이 영화 핵노잼 ㅠㅠ')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ybiSO0142-oc"},"source":["sentiment_predict('이딴게 영화냐 ㅉㅉ')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8O25qZvf3Ao8"},"source":["sentiment_predict('감독 뭐하는 놈이냐?')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zqLrvLSs3BgE"},"source":["sentiment_predict('와 개쩐다 정말 세계관 최강자들의 영화다')"],"execution_count":null,"outputs":[]}]}